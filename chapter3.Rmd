# Logistic regression


```{r}
date()
```


```{r}
#Setting Working Directory
setwd("C:/IODS/IODS-project")

#loading the data 
alc <- read.table("data/alc.csv", sep = ",", header=TRUE, stringsAsFactors = TRUE)

variable.names(alc)
```


The data set described and studied in this chapter is a combination of two studies investigating how demographic, social and school related factors affect the students achievement in secondary education of two Portuguese schools. The performance is investigated in two subjects, mathematics (.m) and Portuguese language (.p) for three different time points G1(first), G2(second) and G3(final).

The purpose of the analysis performed in this chapter is to use the information in the data set to assess how alcohol consumption influence the result of students and study factors that in turn affect the alcohol consumption, to enable directed measures.   

Since alcohol consumption in the world, in general, varies between male and female in that men both drink more often and have a higher tendency to binge drink than woman, we hypothesis that this will be the case also in the current data set and for all graphical comparison a distinguishing will be performed between male and female using color. 

The hypothesis is that a high alcohol consumption would result in a higher risk of the student being absent from and failing to pass the classes, since alcohol consumption impair the brains working capacity and body functioning in multiple ways, e.g., damaging the sleep pattern, decreased memory capacity and increased risk for illness. with the same background, the hypothesis would be that even if the student are not failing the class the final grade would be affected.

**To give more meaning to the graphs investigating the variables and alcohol consumption lets first look at the within variable distribution of sex and alcohol consumption**

```{r}
# access the tidyverse libraries tidyr, dplyr, ggplot2
library(tidyr); library(dplyr); library(ggplot2); library(cowplot)


alc_interest <- select(alc, one_of("high_use", "sex"))

gather(alc_interest) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") +
geom_bar() +
ggtitle("Figure 1")

summary(alc$sex)
summary(alc$high_use)
```

As we can read from figure 1 and associated summery tabels:

* There is almost as many men and woman in the data set, with only a slightly higher portion of female students. 

  and

* About $2/7$ of the students have a high use of alcohol. 


**To then asses the relationship between the variables and high alcohol a second set of graphs is produced**
```{r}

p1 <- ggplot(data = alc, aes(x = alc_use, fill = sex)) + 
geom_bar() + 
ggtitle("Sex dependent alcohole use")

p2 <- ggplot(data = alc, aes(x = high_use, y = failures, fill = sex, color = sex)) + 
geom_boxplot() + 
ggtitle("High alcohole use and class failure")

p3 <- ggplot(data = alc, aes(x = high_use, y = absences, fill = sex, color = sex)) + 
geom_boxplot() + 
ggtitle("High alcohole use and absence")

p4 <- ggplot(data = alc, aes(x = high_use, y = G3, fill = sex, color = sex)) + 
geom_boxplot() + 
ggtitle("High alcohol use and final grades")

p <- plot_grid(p1, p3, p4, p2, labels = c('A', 'B', 'C', 'D'))

title <- ggdraw() + 
draw_label( "Figure 2",
    fontface = 'bold', x = 0, hjust = 0 ) +
  theme(
    # add margin on the left of the drawing canvas,
    # so title is aligned with left edge of first plot
    plot.margin = margin(0, 0, 0, 7))
plot_grid( title, p, ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1))

summary(alc$absences)
summary(alc$failures)
summary(alc$G3)

```
Figure 2 shows an overview of the four factors described in relation to alcohol consumption, the summary of the within variable distribution not previously described is showed in associated tables. High consumption has been defined as an average grading of workday and weekend alcohol consumption as 3-5 on a likert scale ranging from 1 (very low) to 5 (very high), the full distribution is showed in panel A. As we can see in panel A, the hypothesis that the male students would drink more alcohol than female seem to be correct and hence our population is also representative for the society in general.

The initial graphs showed in panel B and C also suggest that the hypothesis that high alcohol consumption would result in higher absence and lower final grades could be true.

In contrast panel D suggest that the alcohol consumption would not affect the number of students failing in the passing the class to much. However the reader should notice that in our data sett the amount of student falling to pass classes is very few in general and an affect could be more prominent with a larger population. 

Let us anyway keep the failing variable hypothesis and see how it is handled in a logic regression model, assessing the affect of high alcohol use on the four variables with high use as a binomial factor. 

**A logic regression model is produced with the variables and odds ratio and confidence intervals are calculated to investigate the statistical relationship**

```{r}
# find the model with glm()
m <- glm(high_use ~ failures + absences + sex + G3, data = alc, family = "binomial")

# print out a summary of the model
summary(m)

# print out the coefficients of the model
coef(m)

# compute odds ratios (OR)
OR <- coef(m) %>% exp

# compute confidence intervals (CI)
CI <- confint(m) %>% exp

# print out the odds ratios with their confidence intervals
cbind(OR, CI)
```
As we can see from the initial regression model alcohol use is significantly related to the sex of the student, where significantly more male student have reported high alcohol consumption. The hypothesis that high alcohol use would result in more absence are also supported by the regression model. However, while a slight affect of alcohol consumption on final grade was suggested by the graph, the model didn't find any significant affect and in contrast the model propose that there is a slight significant relationship between alcohol use and failure of class. 

The information showed by the odds ratio (OR) and confidence interval (CI) is also in line with the information found in the model summary, with rather high ORs for sex and failure, an OR a bit away from 1 for absence, but also an OR very close to 1 for final grades. For the three significant variabels the CIs are also positive for both percentiles, while for grades the CI is on oposite sides of 1 and rather tight. 

Since the final grade (G3) is non significant in the first regression model, a second model with only three variables are created before used for prediction. 

**A second model are created and the predicted power is calculated using the second model**

```{r}
# fit the model
m2 <- glm(high_use ~ failures + absences + sex, data = alc, family = "binomial")

# predict() the probability of high_use
probabilities <- predict(m2, type = "response")

# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability > 0.5)

# see the last ten original classes, predicted probabilities, and class predictions
select(alc, failures, absences, sex, high_use, probability, prediction) %>% tail(10)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)
```

```{r}
# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(alc, aes(x = probability, y = high_use, col = prediction)) + 
  geom_point() +
  ggtitle("Figure 3")
g

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table %>% addmargins
```

```{r}
# define a loss function (average prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)

```
Average number of wrong predictions with the second model is ~0.2 


**A 10 - cross validation is performed for the model**
```{r}
# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]

```
With 10 fold cross validation, the average number of wrong predictions is ~0.24 - 0.26, wish is similar or slightly lower than the one in the Data Camp exercise. No specific number can be mention since slightly different value is computed each time. 